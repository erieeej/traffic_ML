{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing and Data Merging\n",
    "#Import modules\n",
    "import numpy as np\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "#scipy\n",
    "import scipy.stats as stats\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "#sklearn\n",
    "import sklearn\n",
    "from sklearn import ensemble\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, log_loss, recall_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#for clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#other learners\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "#imblearn\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "#webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "#time series\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "import itertools\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "\n",
    "#warning ignorer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# # #DATAFRAME PICKLE CREATED IN CELLS BELOW INSTEAD OF RUNNING THROUGH ENTIRE PROCESS AFTER RESTARTING\n",
    "# # #import pickled file\n",
    "df = pd.read_pickle(\"df.pkl\")\n",
    "# df.to_csv('uktraffic_acc.csv') \n",
    "#import files\n",
    "\n",
    "ac = pd.read_csv(r'Accident_Information.csv', low_memory=False, chunksize=30000)\n",
    "vc = pd.read_csv(r'Vehicle_Information.csv', low_memory=False, chunksize=30000)\n",
    "Previously, I did not remove \"Data missing or out of range\" from the datasets however through cleaning and checking the value counts I decided to do so for sanity purposes only. Most of the percentages that had this as a value were not a high percentage either. \n",
    "#chunk cleaning and dataframing for accident column\n",
    "acchunk = []\n",
    "for chunk in ac:\n",
    "    acchunk_filter = chunk[\n",
    "        (chunk.Year.astype(int) >= 2010) &\n",
    "        (chunk.Year.astype(int) <= 2017) &\n",
    "        (chunk['Road_Type'] != \"Unknown\") &\n",
    "        (chunk['Junction_Control'] != \"Data missing or out of range\") &\n",
    "        (chunk['Carriageway_Hazards'] != \"Data missing or out of range\") &\n",
    "        (chunk['Junction_Detail'] != \"Data missing or out of range\") &\n",
    "        (chunk['Road_Surface_Conditions'] != \"Data missing or out of range\") &\n",
    "        (chunk['Special_Conditions_at_Site'] != \"Data missing or out of range\") &\n",
    "        (chunk['Weather_Conditions'] != \"Data missing or out of range\") &\n",
    "        (chunk['Latitude'].notnull()) &\n",
    "        (chunk['Longitude'].notnull())\n",
    "    ]\n",
    "    acchunk.append(acchunk_filter)\n",
    "df1 = pd.concat(acchunk)\n",
    "\n",
    "#chunk cleaning for vehicles column\n",
    "vcchunk = []\n",
    "for chunk2 in vc:\n",
    "    vcchunk_filter = chunk2[\n",
    "        (chunk2.Year.astype(int) >= 2010)&\n",
    "        (chunk2.Year.astype(int) <= 2017) &\n",
    "        (chunk2['Driver_Home_Area_Type'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Journey_Purpose_of_Driver'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Junction_Location'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Was_Vehicle_Left_Hand_Drive'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Hit_Object_in_Carriageway'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Skidding_and_Overturning'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Towing_and_Articulation'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Vehicle_Leaving_Carriageway'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Vehicle_Manoeuvre'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Vehicle_Type'] != \"Data missing or out of range\") &\n",
    "        (chunk2['X1st_Point_of_Impact'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Sex_of_Driver'] != \"Data missing or out of range\") &\n",
    "        (chunk2['Age_Band_of_Driver'] != \"Data missing or out of range\")\n",
    "        \n",
    "    ]\n",
    "    vcchunk.append(vcchunk_filter)\n",
    "df2 = pd.concat(vcchunk)\n",
    "#check columns\n",
    "print(\"Accident's Columns:\\n\",df1.columns, \"\\n\")\n",
    "\n",
    "print(\"Vehicle's Columns:\\n\",df2.columns)\n",
    "print('Accident Shape', df1.shape)\n",
    "print('Vehicle Shape',df2.shape)\n",
    "#merge dataframes\n",
    "df = pd.merge(df1,df2)\n",
    "#check columns\n",
    "print(\"Names of Combined Columns:\\n\",df.columns, \"\\n\")\n",
    "print(\"\\nShape:\\n\",df.shape)\n",
    "df.describe(include ='all')\n",
    "### Data Cleaning\n",
    "#check corr b/t Location_Easting_OSGR & Location_Northing_OSGR AND Longitude and Latitude\n",
    "\n",
    "print(df['Location_Easting_OSGR'].corr(df['Longitude']))\n",
    "\n",
    "\n",
    "print(df['Location_Northing_OSGR'].corr(df['Latitude']))\n",
    "#drop Location_Easting_OSGR & Location_Northing_OSGR\n",
    "#because they are the similar to Latitude and Longitude \n",
    "\n",
    "df = df.drop(['Location_Easting_OSGR', 'Location_Northing_OSGR'], axis=1)\n",
    "df.shape\n",
    "#standardize all column names to lowercase, and remove some characters \n",
    "#for ease of use in querying\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df.columns = df.columns.str.replace('.','')\n",
    "df.columns = df.columns.str.replace('(','')\n",
    "df.columns = df.columns.str.replace(')','')\n",
    "#convert date/time to datetime datatype\n",
    "\n",
    "df['date'] = pd.to_datetime((df['date']), format= \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "#df.dtypes\n",
    "#mistyped datatypes\n",
    "\n",
    "df[['did_police_officer_attend_scene_of_accident',\n",
    "    'driver_imd_decile','vehicle_reference',\n",
    "    'vehicle_locationrestricted_lane','1st_road_number',\n",
    "    '2nd_road_number','driver_imd_decile',\n",
    "    'pedestrian_crossing-physical_facilities',\n",
    "   'pedestrian_crossing-human_control']]= df[['did_police_officer_attend_scene_of_accident',\n",
    "    'driver_imd_decile','vehicle_reference',\n",
    "    'vehicle_locationrestricted_lane','1st_road_number',\n",
    "    '2nd_road_number','driver_imd_decile',\n",
    "    'pedestrian_crossing-physical_facilities',\n",
    "   'pedestrian_crossing-human_control']].astype('object')\n",
    "\n",
    "\n",
    "df.columns.to_series().groupby(df.dtypes).groups\n",
    "#### Nulls and Outliers\n",
    "df.isnull().sum().sort_values(ascending=False)/df.shape[0]*100\n",
    "##### 2nd_road_class\n",
    "# #2nd_road_class\n",
    "df['2nd_road_class'].value_counts()/df.shape[0]*100\n",
    "With 40% of non null being unclassified and 39% of the overall 2nd_road_class column being null, I have decided to drop it in it's entirely. \n",
    "df = df.drop(['2nd_road_class'], axis=1)\n",
    "##### driver_imd_decile\n",
    "#driver_imd_decile\n",
    "df['driver_imd_decile'].value_counts()/df.shape[0]*100\n",
    "Since the distribution of categories for 'driver_imd_decile seem very similar, I've decided not to use the mode but \"method='ffill'\"\n",
    "df['driver_imd_decile'].fillna(method='ffill', inplace=True)\n",
    "##### age_of_vehicle\n",
    "df['age_of_vehicle'].describe()\n",
    "df['age_of_vehicle'].median()\n",
    "Changing the nulls of \"age of vehicle\" to median, then creating it as a category\n",
    "#fillna by 7 \n",
    "df['age_of_vehicle'].fillna(7, inplace=True)\n",
    "\n",
    "#group age_of_vehicle\n",
    "#1=0-3, 2=3-5, 3=5-8, 4=8-11, 5=\n",
    "def fixedvehicleage(age):\n",
    "    if age>=0 and age<=120:\n",
    "        return age\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['age_of_vehicle'] = df['age_of_vehicle'].apply(fixedvehicleage)\n",
    "\n",
    "\n",
    "df['age_of_vehicle'] = pd.cut(df['age_of_vehicle'], \n",
    "                             [0,2,5,8,11,14,17,120], labels=['1', '2', '3','4','5','6','7'])\n",
    "\n",
    "##### Model\n",
    "#model\n",
    "df['model'].value_counts()/df.shape[0]*100\n",
    "df['model'].describe()\n",
    "Knowing that there are 28824 unique models for the model column I have decided to use the ffill method on it as well. \n",
    "df['model'].fillna(method='ffill', inplace=True)\n",
    "Note: A lot of the values of \"model' are labeled as \"missing\". I do not want to change these because the model could have actually been missing from the car from the accident or it could not be recognizable at the time of the accident.\n",
    "#### engine_capacity_cc\n",
    "#engine_capacity_cc\n",
    "df['engine_capacity_cc'].describe()\n",
    "I am going to handle both outliers and the null values of engine_capacity_cc using the ideals of quantiles and the interquartile range (IQR).\n",
    "#first I'm going to handle both ends of outliers.\n",
    "#(determine the min and max cuttoffs for detecting the outlier)\n",
    "q75, q25 = np.percentile(df['engine_capacity_cc'].dropna(), [75 ,25])\n",
    "iqr = q75 - q25\n",
    " \n",
    "ecmin = q25 - (iqr*1.5)\n",
    "ecmax = q75 + (iqr*1.5)\n",
    "\n",
    "print(ecmax)\n",
    "print(ecmin)\n",
    "To explain, what I am going to do is use the ecmax number for the maximum engine_capacity_cc and ecmin for my engine_capacity_cc. Then I'm going to take the mean of those and use it as my fillna.\n",
    "df = df[df['engine_capacity_cc']<=ecmax]\n",
    "df = df[df['engine_capacity_cc']>=ecmin]\n",
    "df['engine_capacity_cc'].hist(bins=20)\n",
    "plt.style.use('dark_background')\n",
    "I can accept this distribution and will now check and handle their nulls\n",
    "#check values of 'engine_capacity_cc'\n",
    "df['engine_capacity_cc'].describe()\n",
    "df['engine_capacity_cc'].mean()\n",
    "Going to round this mean value\n",
    "df['engine_capacity_cc'].fillna(1652, inplace=True)\n",
    "Note: After doing the above null fixes, propulsion_code dropped from having 10% null values to 0. (see below). I will continue on and fix lsoa_of_accident_location then drop the rest of the null values with are all <5%.\n",
    "df.isnull().sum().sort_values(ascending=False)/df.shape[0]*100\n",
    "#### lsoa_of_accident_location\n",
    "# #lsoa_of_accident_location\n",
    "df['lsoa_of_accident_location'].value_counts()\n",
    "df['lsoa_of_accident_location'].describe()\n",
    "With 35061 unique variable and a high count amount the top variables I am deciding to do ffill again. \n",
    "df['lsoa_of_accident_location'].fillna(method='ffill', inplace=True)\n",
    "#### Check nulls for again\n",
    "df.isnull().sum().sort_values(ascending=False)/df.shape[0]*100\n",
    "Dropping the remaining nulls that are <1%.\n",
    "#drop the remaining nulls that are <1%\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#last check\n",
    "df.isnull().sum().sort_values(ascending=False)/df.shape[0]*100\n",
    "df.shape\n",
    "df.info()\n",
    "#### More outliers, categorizing, and other cleanup\n",
    "#detecting outliers of numerical columns (all floats/ints excluding lat/long and year)\n",
    "\n",
    "df_num = df[['engine_capacity_cc','number_of_casualties','number_of_vehicles','speed_limit']]\n",
    "\n",
    "df_num.hist( bins=25, grid=False, figsize=(12,8))\n",
    "plt.style.use('dark_background')\n",
    "Column 'speed_limit' seems ok and was previously altered 'engine_capacity_cc'. However, 'number_of_casualties', and 'number_of_vehicles',will be evaluated. \n",
    "# #number_of_casualties\n",
    "df['number_of_casualties'].value_counts()\n",
    "#create casualities grouping\n",
    "\n",
    "def casualities(num_cas):\n",
    "    if num_cas >=1 and num_cas <2:\n",
    "        return \"1\"\n",
    "    elif num_cas >=2 and num_cas <3:\n",
    "        return \"2\"\n",
    "    elif num_cas >=3 and num_cas <4:\n",
    "        return \"3\"\n",
    "    elif num_cas >= 4 and num_cas <5:\n",
    "        return \"4\"\n",
    "    elif num_cas >= 5:\n",
    "        return \"5+\"\n",
    "  \n",
    "    \n",
    "#apply function   \n",
    "df['number_of_casualties']= df['number_of_casualties'].apply(casualities)\n",
    "#number_of_casualties\n",
    "df['number_of_casualties'].value_counts()\n",
    "df['propulsion_code'].value_counts()/df.shape[0]*100\n",
    "#Clean the values for Propulsion Code. \n",
    "df['propulsion_code'] = df['propulsion_code'].replace(to_replace=\"Gas\", value=\"Petrol\")\n",
    "df['propulsion_code'] = df['propulsion_code'].replace(to_replace=\"Gas/Bi-fuel\", value=\"Bio-fuel\")\n",
    "df['propulsion_code'] = df['propulsion_code'].replace(to_replace=\"Petrol/Gas (LPG)\", value=\"LPG Petrol\")\n",
    "df['propulsion_code'] = df['propulsion_code'].replace(to_replace=\"Gas Diesel\", value=\"Diesel\")\n",
    "df['propulsion_code'].value_counts()/df.shape[0]*100\n",
    "### Feature Manipulation Creation and Engineering\n",
    "# #unique values\n",
    "df.nunique().sort_values(ascending=False)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df ['date'].apply(lambda time: time.month)\n",
    "#creating a weekend feature that includes Friday-Sunday\n",
    "df['weekend']= np.where(df['day_of_week'].isin(['Friday', 'Saturday', 'Sunday']), 1, 0)\n",
    "#create time of day feature with Morning Rush, Day, Noon Rush, Afternoon, After Work Rush, Night\n",
    "\n",
    "#time of day dictionary\n",
    "timeofdaygroups = {1: \"Morning Rush (6-10)\",\n",
    "                   2: \"Day (10-12)\",\n",
    "                   3: \"Lunch Rush (12-14)\",\n",
    "                   4: \"Afternoon (14-16)\",\n",
    "                   5: \"After Work Rush (16-18)\",\n",
    "                   6: \"Evening (18-22)\",\n",
    "                   7: \"Night (22-6)\"}\n",
    "#pull time data and create hour column\n",
    "df['hour'] = df['time'].str[0:2]\n",
    " \n",
    "#convert to numeric    \n",
    "df['hour'] =  pd.to_numeric(df['hour'])\n",
    "\n",
    "#convert to integer\n",
    "df['hour'] = df['hour'].astype('int')\n",
    "#create time_of_day grouping\n",
    "\n",
    "def daygroup(hour):\n",
    "    if hour >= 6 and hour < 10:\n",
    "        return \"1\"\n",
    "    elif hour >= 10 and hour < 12:\n",
    "        return \"2\"\n",
    "    elif hour >= 12 and hour < 14:\n",
    "        return \"3\"\n",
    "    elif hour >= 14 and hour < 16:\n",
    "        return \"4\"\n",
    "    elif hour >= 16 and hour < 18:\n",
    "        return \"5\"\n",
    "    elif hour >= 18 and hour < 22:\n",
    "        return \"6\"\n",
    "    else:\n",
    "        return \"7\"\n",
    "    \n",
    "#apply function   \n",
    "#time of day function\n",
    "df['time_of_day']= df['hour'].apply(daygroup)   \n",
    "df[['weekend','day_of_week','time', 'time_of_day']].tail(10)\n",
    "#vehicle_type\n",
    "df['vehicle_type'].value_counts()/df.shape[0]*100\n",
    "I want to condense the vehicle type variables. \n",
    "#motorcycles\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Motorcycle over 500cc\", \n",
    "                                                        value=\"Motorcycle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\n",
    "                                                        \"Motorcycle over 125cc and up to 500cc\",\n",
    "                                                        value=\"Motorcycle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Motorcycle 125cc and under\", \n",
    "                                                value=\"Motorcycle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Motorcycle 50cc and under\", \n",
    "                                                        value=\"Motorcycle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Electric motorcycle\", \n",
    "                                                        value=\"Motorcycle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Motorcycle - unknown cc\", \n",
    "                                                        value=\"Motorcycle\")\n",
    "\n",
    "\n",
    "#Goods_vehicle\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\n",
    "                                                        \"Van / Goods 3.5 tonnes mgw or under\", \n",
    "                                                        value=\"Goods Vehicle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Goods over 3.5t. and under 7.5t\", \n",
    "                                                        value=\"Goods Vehicle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Goods vehicle - unknown weight\", \n",
    "                                                        value=\"Goods Vehicle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Goods 7.5 tonnes mgw and over\", \n",
    "                                                        value=\"Goods Vehicle\")\n",
    "\n",
    "#car\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Taxi/Private hire car\", \n",
    "                                                        value=\"Car\")\n",
    "\n",
    "\n",
    "#bus\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Minibus (8 - 16 passenger seats)\", \n",
    "                                                        value=\"Bus\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\n",
    "                                                        \"Bus or coach (17 or more pass seats)\", \n",
    "                                                        value=\"Bus\")\n",
    "\n",
    "#other vehicle\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Agricultural vehicle\", \n",
    "                                                        value=\"Other Vehicle\")\n",
    "df['vehicle_type'] = df['vehicle_type'].replace(to_replace=\"Other vehicle\", \n",
    "                                                        value=\"Other Vehicle\")\n",
    "\n",
    "#vehicle_type\n",
    "df['vehicle_type'].value_counts()/df.shape[0]*100\n",
    "Create more condense groups for age band of driver in order to deal with some potential outliers.\n",
    "#age_band_of_driver \n",
    "df['age_band_of_driver'].value_counts()/df.shape[0]*100\n",
    "#I did this before hand because as \"Over 75\", it wouldnt convert in the codes below\n",
    "df['age_band_of_driver']=df['age_band_of_driver'].replace(\"Over 75\",\"75-100\")\n",
    "age1 = [\"0 - 5\", \"6 - 10\", \"11 - 15\"]\n",
    "age2 = [\"16 - 20\",\"21 - 25\"]\n",
    "age3 = [\"26 - 35\",\"36 - 45\"]\n",
    "age4 = [\"46 - 55\", \"56 - 65\"]\n",
    "age5 = [\"66 - 75\", \"75-100\"]\n",
    "#over 75 wouldnt work in the string so I did it separately\n",
    "for (row, col) in df.iterrows():\n",
    "\n",
    "    if str.lower(col.age_band_of_driver) in age1:\n",
    "        df['age_band_of_driver'].replace(to_replace=col.age_band_of_driver, \n",
    "                                         value='Under 16', inplace=True)\n",
    "\n",
    "    if str.lower(col.age_band_of_driver) in age2:\n",
    "        df['age_band_of_driver'].replace(to_replace=col.age_band_of_driver, \n",
    "                                         value='16-25', inplace=True)\n",
    "    \n",
    "    if str.lower(col.age_band_of_driver) in age3:\n",
    "        df['age_band_of_driver'].replace(to_replace=col.age_band_of_driver, \n",
    "                                         value='26-45', inplace=True)\n",
    "    if str.lower(col.age_band_of_driver) in age4:\n",
    "        df['age_band_of_driver'].replace(to_replace=col.age_band_of_driver, \n",
    "                                         value='46-65', inplace=True)\n",
    "    if str.lower(col.age_band_of_driver) in age5:\n",
    "        df['age_band_of_driver'].replace(to_replace=col.age_band_of_driver, \n",
    "                                         value='Over 65', inplace=True)\n",
    "#age_band_of_driver\n",
    "print(\"Distinct responses for age_band_of_driver:\\n\", set(df['age_band_of_driver']))\n",
    "# number_of_vehicles\n",
    "df['number_of_vehicles'].value_counts()/df.shape[0]*100\n",
    "#group number_of_vehicles\n",
    "\n",
    "def vehicles(num_veh):\n",
    "    if num_veh >=1 and num_veh <2:\n",
    "        return \"1\"\n",
    "    elif num_veh >=2 and num_veh <3:\n",
    "        return \"2\"\n",
    "    elif num_veh >=3 and num_veh <4:\n",
    "        return \"3\"\n",
    "    elif num_veh >= 4: \n",
    "        return \"4+\"\n",
    "  \n",
    "#apply function   \n",
    "df['number_of_vehicles']= df['number_of_vehicles'].apply(vehicles)\n",
    "# number_of_vehicles\n",
    "df['number_of_vehicles'].value_counts()/df.shape[0]*100\n",
    "df['number_of_vehicles'].dtypes\n",
    "df['number_of_vehicles']=df['number_of_vehicles'].astype('object')\n",
    "#creating seasons column for ML\n",
    "\n",
    "#creating season column\n",
    "\n",
    "def getSeason(month):\n",
    "    if (month == 12 or month == 1 or month == 2):\n",
    "       return \"winter\"\n",
    "    elif(month == 3 or month == 4 or month == 5):\n",
    "       return \"spring\"\n",
    "    elif(month == 6 or month== 7 or month == 8):\n",
    "       return \"summer\"\n",
    "    else:\n",
    "       return \"fall\"\n",
    "\n",
    "df['season'] = df['month'].apply(getSeason)\n",
    "# number_of_vehicles\n",
    "df['season'].value_counts()/df.shape[0]*100\n",
    "#go back to engine capacity CC and crete groups\n",
    "df.engine_capacity_cc.hist()\n",
    "def enginecap(eng_cc):\n",
    "    if eng_cc <=1500:\n",
    "        return \"small engine cc\"\n",
    "    if eng_cc >1500 and eng_cc <=2000:\n",
    "        return \"medium engine cc\"\n",
    "    if eng_cc >2000:\n",
    "        return \"large engine cc\"\n",
    "\n",
    "\n",
    "df['engine_capacity_cc_size'] = df['engine_capacity_cc'].apply(enginecap)\n",
    "df.engine_capacity_cc_size.value_counts()\n",
    "#Put above pickle in next full run\n",
    "#create new column for Machine Learning and Visualization with Not Serious and Serious\n",
    "df['accident_seriousness'] = df['accident_severity']\n",
    "df['accident_seriousness'] = df['accident_seriousness'].replace(to_replace=\"Slight\", \n",
    "                                                                value=\"Not Serious\")\n",
    "df['accident_seriousness'] = df['accident_seriousness'].replace(to_replace=\"Serious\",\n",
    "                                                                value=\"Serious\")\n",
    "df['accident_seriousness'] = df['accident_seriousness'].replace(to_replace=\"Fatal\", \n",
    "                                                                value=\"Serious\")\n",
    "df.shape\n",
    "df.accident_seriousness.value_counts()\n",
    "#pickling everything to speed up restarting\n",
    "df.to_pickle(\"df.pkl\")\n",
    "#import pickled file\n",
    "df = pd.read_pickle(\"df.pkl\")\n",
    "df.head()\n",
    "### General Visualizations\n",
    "accidentsperyear = df.groupby(['year'])['accident_index'].count()\n",
    "\n",
    "# prepare plot\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(10,5))\n",
    "colors = sns.color_palette(\"plasma\", n_colors=7)\n",
    "sns.barplot(accidentsperyear.index,accidentsperyear.values, palette=colors)\n",
    "sns.despine(top=True, right=True, left=True, bottom=True)\n",
    "plt.title(\"Accidents Per Year\",fontsize=20,fontweight=\"bold\")\n",
    "plt.xlabel(\"\\nYear\", fontsize=15, fontweight=\"bold\")\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "plt.savefig('accidentsperyear.png')\n",
    "plt.tight_layout()\n",
    "\n",
    "accidentspermonth = df.groupby(['month'])['accident_index'].count()\n",
    "\n",
    "# prepare plot\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(20,10))\n",
    "colors = sns.color_palette(\"plasma_r\", n_colors=12)\n",
    "mt=sns.barplot(accidentspermonth.index,accidentspermonth.values, palette=colors)\n",
    "sns.despine(top=True, right=True, left=True, bottom=True)\n",
    "#ax is the axes instance\n",
    "group_labels = ['Jan', 'Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec' ]\n",
    "\n",
    "mt.set_xticklabels(group_labels)\n",
    "plt.title(\"Accidents Per Month\",fontsize=20,fontweight=\"bold\")\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"\\nMonth\", fontsize=15, fontweight=\"bold\")\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "plt.savefig('accidentspermonth.png')\n",
    "plt.tight_layout()\n",
    "\n",
    "weekdays = ['Monday', 'Tuesday','Wednesday','Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "accweekday = df.groupby(['year', 'day_of_week']).size()\n",
    "accweekday = accweekday.rename_axis(['year', 'day_of_week'])\\\n",
    "                               .unstack('day_of_week')\\\n",
    "                               .reindex(columns=weekdays)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.style.use('dark_background')\n",
    "sns.heatmap(accweekday, cmap='plasma_r')\n",
    "plt.title('\\nAccidents by Weekday per Year\\n', fontsize=14, fontweight='bold')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig('accidentsbyweekdayperyear.png')\n",
    "plt.show()\n",
    "Fridays are the day of the week where the most accidents occur.\n",
    "accidentsperseason = df.groupby(['season'])['accident_index'].count()\n",
    "seaord=['spring', 'summer', 'fall','winter']\n",
    "# prepare plot\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "sns.barplot(accidentsperseason.index,accidentsperseason.values, order=seaord, \n",
    "            saturation=1, palette='magma_r')\n",
    "sns.despine(top=True, right=True, left=True, bottom=True)\n",
    "plt.title(\"Accidents Per Season\",fontsize=20,fontweight=\"bold\")\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"\\nSeason\", fontsize=15, fontweight=\"bold\")\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('accidentsperseason.png')\n",
    "\n",
    "#\"Morning Rush (6-10)\", \"Day (10-12)\", \"Lunch Rush (12-14)\",\"Afternoon (14-16)\",\n",
    "#\"After Work Rush (16-18)\", \"Evening (18-22)\", \"Night (22-6)\"\n",
    "\n",
    "timeofdaygroups = {'1': \"Morning Rush\",\n",
    "                   '2': \"Day\",\n",
    "                   '3': \"Lunch Rush\",\n",
    "                   '4': \"Afternoon\",\n",
    "                   '5': \"After Work Rush\",\n",
    "                   '6': \"Evening\",\n",
    "                   '7': \"Night\"}\n",
    "df['time_of_day']=df['time_of_day'].map(timeofdaygroups)\n",
    "accidentspertod = df.groupby(['time_of_day'])['accident_index'].count()\n",
    "\n",
    "# prepare plot\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(15,10))\n",
    "tod=[\"Morning Rush\", \"Day\", \"Lunch Rush\", \"Afternoon\",\n",
    "     \"After Work Rush\", \"Evening\", \"Night\"]\n",
    "sns.barplot(accidentspertod.index,accidentspertod.values, order=tod, palette='rainbow')\n",
    "sns.despine(top=True, right=True, left=True, bottom=True)\n",
    "plt.title(\"Accidents Per Time of Day\",fontsize=20,fontweight=\"bold\")\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.xlabel(\"\", fontsize=15, fontweight=\"bold\")\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('accidentspertod.png')\n",
    "\n",
    "### Accident Forecasting with Tableau\n",
    "%%HTML\n",
    "<div class='tableauPlaceholder' id='viz1572176706313' style='position: relative'><noscript><a href='https:&#47;&#47;github.com&#47;GenTaylor&#47;Traffic-Accident-Analysis'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ac&#47;AccidentForecasting&#47;AccidentForecasting&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='AccidentForecasting&#47;AccidentForecasting' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ac&#47;AccidentForecasting&#47;AccidentForecasting&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1572176706313');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>\n",
    "According to the forecasting above, traffic accidents will be slightly lower than years before but following similar trends throughout the months. \n",
    "\n",
    "Below is a screenshot of the above forecasting. I put this here just in case there is trouble viewing it. If you would like to view the actual worksheet for it, please click [here](https://public.tableau.com/profile/genesis.taylor#!/vizhome/AccidentForecasting/AccidentForecasting).\n",
    "\n",
    "![timeforecastingscreenshot.PNG](https://raw.githubusercontent.com/GenTaylor/Traffic-Accident-Analysis/master/timeforecastingscreenshot.PNG)\n",
    "### Correlations\n",
    "For correlation I used both Pearson and Spearman just in case there would be discrepancies. The order may have slightly varied but the \"highest\" correlated remained the same.\n",
    "#correlation by accident severity pearson\n",
    "corrdf=df.apply(LabelEncoder().fit_transform)\n",
    "sc = StandardScaler()\n",
    "corrdf = sc.fit_transform(corrdf)\n",
    "corrdf=pd.DataFrame(data=corrdf,columns=df.columns)\n",
    "corr=corrdf.corr()['accident_seriousness']\n",
    "corr[np.argsort(corr,axis=0)[::-1]]\n",
    "corr_spear=corrdf.corr(method='spearman')['accident_seriousness']\n",
    "corr_spear[np.argsort(corr_spear,axis=0)[::-1]]\n",
    "Looking at this I wanted to visualize some of the higher pos/negative correlations against accident severity.\n",
    "#### Chi-Squared Test\n",
    "\n",
    "Before these visualizations were done, I wanted to be sure that the visualizations were of some importance to accident_seriousness. For this, the chi-squared test was used.\n",
    "\"\"\"chisquare algorithm from \n",
    "http://www.insightsbot.com/blog/2AeuRL/chi-square-feature-selection-in-python \"\"\"\n",
    "\n",
    "    \n",
    "class ChiSquare:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.p = None #P-Value\n",
    "        self.chi2 = None #Chi Test Statistic\n",
    "        self.dof = None\n",
    "        \n",
    "        self.dfObserved = None\n",
    "        self.dfExpected = None\n",
    "        \n",
    "    def _print_chisquare_result(self, colX, alpha):\n",
    "        result = \"\"\n",
    "        if self.p<alpha:\n",
    "            result=\"The column {0} is IMPORTANT for Prediction\".format(colX)\n",
    "        else:\n",
    "            result=\"The column {0} is NOT an important predictor. (Discard {0} from model)\".format(colX)\n",
    "\n",
    "        print(result)\n",
    "        \n",
    "    def TestIndependence(self,colX,colY, alpha=0.05):\n",
    "        X = self.df[colX].astype(str)\n",
    "        Y = self.df[colY].astype(str)\n",
    "        \n",
    "        self.dfObserved = pd.crosstab(Y,X) \n",
    "        chi2, p, dof, expected = stats.chi2_contingency(self.dfObserved.values)\n",
    "        self.p = p\n",
    "        self.chi2 = chi2\n",
    "        self.dof = dof \n",
    "        \n",
    "        self.dfExpected = pd.DataFrame(expected, columns=self.dfObserved.columns, \n",
    "                                       index = self.dfObserved.index)\n",
    "        \n",
    "        self._print_chisquare_result(colX,alpha)\n",
    "\n",
    "#Initialize ChiSquare Class\n",
    "cT = ChiSquare(df)\n",
    "\n",
    "#Feature Selection\n",
    "testColumns = ['accident_index', '1st_road_class', '1st_road_number','2nd_road_number', \n",
    "               'carriageway_hazards', 'date', 'day_of_week', \n",
    "               'did_police_officer_attend_scene_of_accident','junction_control', \n",
    "               'junction_detail', 'latitude', 'light_conditions', 'local_authority_district',\n",
    "               'local_authority_highway', 'longitude','lsoa_of_accident_location', \n",
    "               'number_of_casualties', 'number_of_vehicles', 'pedestrian_crossing-human_control',\n",
    "               'pedestrian_crossing-physical_facilities', 'police_force','road_surface_conditions', \n",
    "               'road_type', 'special_conditions_at_site', 'speed_limit', 'time', \n",
    "               'urban_or_rural_area', 'weather_conditions', 'year', 'inscotland', \n",
    "               'age_band_of_driver', 'age_of_vehicle', 'driver_home_area_type', \n",
    "               'driver_imd_decile', 'engine_capacity_cc','hit_object_in_carriageway', \n",
    "               'hit_object_off_carriageway', 'journey_purpose_of_driver', 'junction_location', \n",
    "               'make', 'model','propulsion_code', 'sex_of_driver', 'skidding_and_overturning',\n",
    "               'towing_and_articulation', 'vehicle_leaving_carriageway',\n",
    "               'vehicle_locationrestricted_lane', 'vehicle_manoeuvre','vehicle_reference',\n",
    "               'vehicle_type', 'was_vehicle_left_hand_drive', 'x1st_point_of_impact', 'month',\n",
    "               'weekend', 'hour', 'time_of_day','season', 'engine_capacity_cc_size']\n",
    "for var in testColumns:\n",
    "    cT.TestIndependence(colX=var,colY=\"accident_seriousness\" )  \n",
    "## Visualizations In Relation to Accident Seriousness\n",
    "#### Method:\n",
    "For my visualizations I have decided to use some of the features with the highest correlations to accident_seriousness:\n",
    "* did_police_officer_attend_scene_of_accident \n",
    "* x1st_point_of_impact \n",
    "* number_of_vehicles  \n",
    "* speed_limit\n",
    "* urban_or_rural_area  \n",
    "* skidding_and_overturning \n",
    "* vehicle_leaving_carriageway \n",
    "* sex_of_driver     \n",
    "* vehicle_type  \n",
    "* vehicle_manoeuvre \n",
    "* engine_capacity_cc \n",
    "* number_of_casualties                           \n",
    "* driver_home_area_type  \n",
    "* age_band_of_driver  \n",
    "* junction_control  \n",
    "* hit_object_off_carriageway\n",
    "* hit_object_in_carriageway \n",
    "* driver_imd_decile *\n",
    "* junction_detail *\n",
    "* junction_location *\n",
    "* propulsion_code *\n",
    "* year *\n",
    "***\n",
    "Note: The columns used were selected because of the absolute value of their correlation in relation to accident_seriousness\n",
    "\n",
    "*columns added after correlation was done after undersampling\n",
    "For visual reasons, two separate dataframes were created, for not serious and serious accidents. I wanted to better scale the data and for me, this was the simplest way of doing so.\n",
    "#dataframe where accidents are Slight\n",
    "not_serious = df[(df['accident_seriousness']==\"Not Serious\")]\n",
    "print(\"Not Serious Group Shape:\", not_serious.shape)\n",
    "\n",
    "not_serious.accident_seriousness.value_counts()\n",
    "#dataframe where accidents are serious\n",
    "serious= df[(df['accident_seriousness']==\"Serious\")]\n",
    "\n",
    "print(\"Serious Group Shape:\", serious.shape)\n",
    "serious.accident_seriousness.value_counts()\n",
    "#map 1, 2, 3 in did_police_officer_attend_scene_of_accident with Yes, No,Self-reported\n",
    "policeattend = {1: \"Yes\", 2:\"No\", 3:\"Self-Reported\"}\n",
    "not_serious['did_police_officer_attend_scene_of_accident']=not_serious['did_police_officer_attend_scene_of_accident'].map(policeattend)\n",
    "df['did_police_officer_attend_scene_of_accident']=df['did_police_officer_attend_scene_of_accident'].map(policeattend)\n",
    "serious['did_police_officer_attend_scene_of_accident']=serious['did_police_officer_attend_scene_of_accident'].map(policeattend)\n",
    "\n",
    "imddecile = {1:\"Most deprived 10%\", 2:\"More deprived 10-20%\", 3:\"More deprived 20-30%\", \n",
    "             4:\"More deprived 30-40%\", 5:\"More deprived 40-50%\", 6:\"Less deprived 40-50%\", \n",
    "             7:\"Less deprived 30-40%\", 8:\"Less deprived 20-30%\", 9:\"Less deprived 10-20%\", \n",
    "             10:\"Least deprived 10%\"}\n",
    "\n",
    "not_serious['driver_imd_decile']=not_serious['driver_imd_decile'].map(imddecile)\n",
    "df['driver_imd_decile']=df['driver_imd_decile'].map(imddecile)\n",
    "serious['driver_imd_decile']=serious['driver_imd_decile'].map(imddecile)\n",
    "\n",
    "#setups for adding frequencies to visualizations\n",
    "dftotal= float(len(df))\n",
    "nstotal= float(len(not_serious))\n",
    "setotal= float(len(serious))\n",
    "\n",
    "#### Did Police Officer Attend Scene Of Accident\n",
    "\n",
    "The below plots will look into if police officers attended the scene of an accident. \n",
    "fig, ax =plt.subplots(1,2,figsize = (15,8))\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "ax1 = sns.countplot( \"did_police_officer_attend_scene_of_accident\", hue=\"accident_seriousness\", \n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 = sns.countplot(\"did_police_officer_attend_scene_of_accident\", hue=\"accident_seriousness\",  \n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Did Police Officer Attend Scene Of Accident\", fontsize=20, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Attendance of Not Serious Accidents', fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Attendance of Serious Accidents', fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number Attended')\n",
    "ax2.set_ylabel('Number Attended')\n",
    "ax1.get_legend().remove()\n",
    "ax2.get_legend().remove()\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('did_police_officer_attend_scene_of_accident.png')\n",
    "fig.show()\n",
    "\n",
    "#### First Point of Impact\n",
    "\n",
    "The below plots show the counts for the first spot in which vehicles were hit in an accident\n",
    "# First Point of Impact Vs Accident Seriousness (Not Serious)\n",
    "fpoa_order =[\"Front\", \"Nearside\", \"Did not impact\", \"Back\", \"Offside\"]\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "ax1 =sns.countplot(\"accident_seriousness\",hue=\"x1st_point_of_impact\", hue_order=fpoa_order,  \n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 = sns.countplot(\"accident_seriousness\",hue=\"x1st_point_of_impact\", hue_order=fpoa_order, \n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"First Point of Impact in Accidents\", fontsize=20, fontweight=\"bold\")\n",
    "ax1.set_xlabel('First Point of Impact of Not Serious Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_xlabel('First Point of Impact of Serious Accidents',  fontsize=15, fontweight=\"bold\")\n",
    "ax1.set_ylabel('First Point of Impact Count', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('')\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('x1st_point_of_impact.png')\n",
    "fig.show()\n",
    "\n",
    "#### Number of Vehicles\n",
    "\n",
    "The below plots show the counts for number of vehicles in each accident.\n",
    "\n",
    "nov_order=[\"1\",\"2\", \"3\", \"4+\"]\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"number_of_vehicles\", hue_order=nov_order,\n",
    "              palette=\"GnBu_d\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 = sns.countplot(\"accident_seriousness\", hue=\"number_of_vehicles\", hue_order=nov_order,\n",
    "              palette=\"GnBu_d\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Number of Vehicles in Accidents\", fontsize=20, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Number of Vehicles of Not Serious Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Number of Vehicles of Serious Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.set_ylabel('')\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('number_of_vehicles.png')\n",
    "fig.show()\n",
    "\n",
    "#### Spe#### Speed Limit vs Accident Seriousness\n",
    "The below graphs show the speed limit by accident in areas where the accidents occured. ed Limit vs Accident Seriousness\n",
    "splt_order=[15, 20,30,40,50,60,70]\n",
    "splt_order2=[20,30,40,50,60,70]\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"speed_limit\", hue_order=splt_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.4f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"speed_limit\", hue_order=splt_order2,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Speed Limit in Accidents\", fontsize=20, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Speed Limit of Not Serious Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Speed Limit of Serious Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('speed_limit.png')\n",
    "fig.show()\n",
    "\n",
    "#### Urban  or Rural  Area vs Accident Seriousness\n",
    "The graphs below show whether the accidents occured in an Urban or Rural Area.\n",
    "fig, ax =plt.subplots(1,2,figsize = (15,8))\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "ax1 =sns.countplot(\"accident_seriousness\",  hue=\"urban_or_rural_area\",\n",
    "              palette=\"PuBu\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 = sns.countplot(\"accident_seriousness\",  hue=\"urban_or_rural_area\",\n",
    "              palette=\"PuBu\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Urban or Rural Areas vs Accidents\", fontsize=20, fontweight=\"bold\")\n",
    "ax1.set_xlabel('\\nUrban or Rural Areas vs Not Serious Accidents', fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel('\\nUrban or Rural Areas vs Serious Accidents', fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.set_ylabel('')\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('urban_or_rural_area.png')\n",
    "fig.show()\n",
    "\n",
    "#### Skidding and Overturning vs Seriousness\n",
    "The below graphs show if any skidding, jackniffing, and/or overturnning occured in the acccident.\n",
    "sao_order=[\"None\", \"Skidded\", \"Skidded and overturned\", \"Overturned\", \"Jackknifed\", \n",
    "           \"Jackknifed and overturned\"]\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"skidding_and_overturning\", hue_order=sao_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.3f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"skidding_and_overturning\", hue_order=sao_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.3f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Skidding and Overturning in Accidents\", fontsize=20, fontweight=\"bold\")\n",
    "ax1.set_xlabel('\\nSkidding and Overturning in Not Serious Accidents', fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel('\\nSkidding and Overturning in Serious Accidents', fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('skidding_and_overturning.png')\n",
    "fig.show()\n",
    "\n",
    "#### Vehicle Leaving Carriageway vs Seriousness\n",
    "The below graphs show if a vehicle left the carriageway, and if they did, where did they do so.\n",
    "vlc_order=[\"Did not leave carriageway\", \"Straight ahead at junction\", \"Nearside\", \n",
    "           \"Offside\", \"Offside on to central reservation\", \"Nearside and rebounded\", \n",
    "           \"Offside - crossed central reservation\", \"Offside and rebounded\", \n",
    "           \"Offside on to centrl res + rebounded\"]\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"vehicle_leaving_carriageway\", hue_order=vlc_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"vehicle_leaving_carriageway\", hue_order=vlc_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Vehicle Leaving Carriageway in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Not Serious Accidents\\n\\n', fontsize=13, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Serious Accidents', fontsize=13, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('vehicle_leaving_carriageway.png')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#### Sex of Driver vs Seriousness\n",
    "The below graphs show the sex of the drivers in the accidents.\n",
    "sod_order=[\"Female\", \"Male\", \"Not known\"]\n",
    "\n",
    "fig, ax =plt.subplots(1,2,figsize = (15,8))\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"sex_of_driver\", hue_order=sod_order,\n",
    "              palette=\"magma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 = sns.countplot(\"accident_seriousness\", hue=\"sex_of_driver\", hue_order=sod_order,\n",
    "              palette=\"magma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Sex of Driver in Accidents\", fontsize=20, fontweight=\"bold\")\n",
    "ax1.set_xlabel('\\nSex of Driver in Not Serious Accidents', fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel('\\nSex of Driver in Serious Accidents', fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.set_ylabel('')\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('sex_of_driver.png')\n",
    "fig.show()\n",
    "\n",
    "#### Vehicle Type vs Seriousness\n",
    "The graphs below are about the number of accidents by type of vehicle.\n",
    "vt_order=['Bus', 'Car', 'Goods Vehicle', 'Motorcycle', 'Other Vehicle']\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"vehicle_type\", hue_order=vt_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"vehicle_type\", hue_order=vt_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Vehicle Type in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Vehicle Type in Not Serious Accidents\\n\\n', fontsize=13, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Vehicle Type in Serious Accidents', fontsize=13, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('vehicle_type.png')\n",
    "fig.show()\n",
    "#### Vehicle Manoeuvres\n",
    "\n",
    "The graphs below depict the types of moves vehicles made that led to the accident. \n",
    "vm_order=['Turning right', 'Going ahead other', 'Going ahead right-hand bend',\n",
    "          'Slowing or stopping', 'Turning left', 'Waiting to go - held up',\n",
    "          'Waiting to turn right', 'Overtaking static vehicle - offside' ,\n",
    "          'Parked', 'Overtaking - nearside', 'U-turn', 'Changing lane to right', \n",
    "          'Reversing', 'Waiting to turn left', 'Changing lane to left',\n",
    "          'Going ahead left-hand bend', 'Overtaking moving vehicle - offside', 'Moving off']\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"vehicle_manoeuvre\",hue_order=vm_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"vehicle_manoeuvre\",hue_order=vm_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Vehicle Manuevers in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "\n",
    "ax1.set_xlabel('Vehicle Manuevers in Not Serious Accidents\\n\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Vehicle Manuevers in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.tight_layout() # No overlap of subplots\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('vehicle_manoeuvre.png')\n",
    "fig.show()\n",
    "#### Driver Home Type Area\n",
    "This area is another look at the type of area the accident occured in, whether Rural, Urban, or Small Town.\n",
    "dhoa_order=['Urban area', 'Rural', 'Small town']\n",
    "\n",
    "fig, ax =plt.subplots(1,2,figsize = (15,8))\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"driver_home_area_type\", hue_order=dhoa_order,\n",
    "              palette=\"magma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "ax2 = sns.countplot(\"accident_seriousness\", hue=\"driver_home_area_type\", hue_order=dhoa_order,\n",
    "              palette=\"magma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "fig.suptitle(\"Driver Home Type Area in Accidents\", fontsize=20, fontweight=\"bold\")\n",
    "ax1.set_xlabel('\\nDriver Home Type Area in Not Serious Accidents', fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel('\\nDriver Home Type Area in Serious Accidents', fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.set_ylabel('')\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('driver_home_area.png')\n",
    "fig.show()\n",
    "\n",
    "#### Age Band of Driver\n",
    "Thr graphs below show accidents by age groups of the drivers.\n",
    "#age_band_of_driver\n",
    "abod_order=['Under 16', '16-25', '26-45', '46-65','Over 65']\n",
    "\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"age_band_of_driver\", hue_order=abod_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"age_band_of_driver\", hue_order=abod_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Age Band of Driver in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Age Band of Driver in Not Serious Accidents\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Age Band of Driver in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('age_band_of_driver.png')\n",
    "fig.show()\n",
    "\n",
    "#### Junction Control\n",
    "The following graphs show what type of traffic signs or signals were up in the accident area, if any.\n",
    "jc_order = ['Give way or uncontrolled', 'Auto traffic signal', 'Authorised person',\n",
    "            'Stop sign','Not at junction or within 20 metres']\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"junction_control\", hue_order=jc_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"junction_control\", hue_order=jc_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Junction Control in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Junction Control in Not Serious Accidents\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Junction Control in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('junction_control.png')\n",
    "fig.show()\n",
    "\n",
    "#### Hit Object Off Carriageway\n",
    "The following graphs show if a vehicle hit an object off of the road and what object, if they hit one during the accident.\n",
    "hooffc_order=['None', 'Lamp post', 'Road sign or traffic signal', 'Other permanent object',\n",
    "              'Entered ditch', 'Tree', 'Near/Offside crash barrier','Central crash barrier',\n",
    "              'Bus stop or bus shelter', 'Telegraph or electricity pole', 'Submerged in water',\n",
    "              'Wall or fence']\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"hit_object_off_carriageway\", hue_order=hooffc_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.3f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"hit_object_off_carriageway\", hue_order=hooffc_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Objects Hit Off Carriageway in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Objects Hit Off Carriageway in Not Serious Accidents\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Objects Hit Off Carriageway in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('hit_object_off_carriageway.png')\n",
    "fig.show()\n",
    "\n",
    "#### Hit Object In Carriageway\n",
    "The following graphs show if a vehicle hit an object on the road and what object, if they hit one during the accident.\n",
    "hoinc_order=['None', 'Kerb', 'Other object', 'Bollard or refuge', 'Parked vehicle',\n",
    "             'Road works', 'Open door of vehicle', 'Central island of roundabout',\n",
    "             'Previous accident', 'Bridge (side)', 'Any animal (except ridden horse)',\n",
    "             'Bridge (roof)']\n",
    "\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,12))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"hit_object_in_carriageway\", hue_order=hoinc_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.3f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"hit_object_in_carriageway\", hue_order=hoinc_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.3f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Objects Hit in Carriageway in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Objects Hit in Carriageway in Not Serious Accidents\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Objects Hit in Carriageway in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('hit_object_in_carriageway.png')\n",
    "fig.show()\n",
    "\n",
    "#### Driver IMD Decile\n",
    "The Driver IMD Decile is the score for the deprivation of an area. The graphs below show accidents by how deprived an area was at the time of the accident. \n",
    "imd_order=[\"Least deprived 10%\", \"Less deprived 10-20%\", \"Less deprived 20-30%\", \n",
    "           \"Less deprived 30-40%\",\"Less deprived 40-50%\",\"Most deprived 10%\",\n",
    "           \"More deprived 10-20%\", \"More deprived 20-30%\", \"More deprived 30-40%\",\n",
    "           \"More deprived 40-50%\"]\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,15))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"driver_imd_decile\", hue_order=imd_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"driver_imd_decile\", hue_order=imd_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Driver Area Deprivation Scores in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Driver Area Deprivation Scores in Not Serious Accidents\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Driver Area Deprivation Scores in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('driver_imd_decile.png')\n",
    "fig.show()\n",
    "#### Junction Detail\n",
    "The following graphs show the road features in relations to where the accidents occured.\n",
    "jud_order=['T or staggered junction', 'Mini-roundabout', 'Crossroads',\n",
    "           'Private drive or entrance', 'More than 4 arms (not roundabout)',\n",
    "           'Roundabout', 'Slip road', 'Other junction','Not at junction or within 20 metres']\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,15))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"junction_detail\", hue_order=jud_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"junction_detail\", hue_order=jud_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Junction Details in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Junction Details in Not Serious Accidents\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Junction Details in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('junction_detail.png')\n",
    "fig.show()\n",
    "\n",
    "#### Junction Location\n",
    "The graphs below show where the accidents occured on the roads.\n",
    "jul_order=['Mid Junction - on roundabout or on main road', 'Entering main road',\n",
    "           'Approaching junction or waiting/parked at junction approach',\n",
    "           'Cleared junction or waiting/parked at junction exit', 'Leaving main road',\n",
    "           'Leaving roundabout', 'Entering roundabout', 'Entering from slip road',\n",
    "           'Not at or within 20 metres of junction']\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,15))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"junction_location\", hue_order=jul_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"junction_location\", hue_order=jul_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Junction Locations in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Junction Locations in Not Serious Accidents\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Junction Locations in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=15, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.savefig('junction_location.png')\n",
    "fig.show()\n",
    "\n",
    "#### Propulsion Code\n",
    "The propulsion ode is the type of fuel used to power the car. The graphs below show what type of fuel was used in the vehicles in the accidents.\n",
    "pd_order=['Petrol', 'Heavy oil', 'Hybrid electric', 'Bio-fuel', 'LPG Petrol', 'Diesel',\n",
    "          'Fuel cells', 'New fuel technology', 'Electric diesel']\n",
    "pd_order2=['Petrol', 'Heavy oil', 'Hybrid electric', 'Bio-fuel', 'LPG Petrol', 'Electric diesel']\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,15))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"propulsion_code\", hue_order=pd_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"propulsion_code\", hue_order=pd_order2,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Propulsion Codes in Accidents\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Propulsion Codes in Not Serious Accidents\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Propulsion Codes in Serious Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('propulsion_code.png')\n",
    "fig.show()\n",
    "\n",
    "#### Year\n",
    "The year of the accidents.\n",
    "year_order=[2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "\n",
    "\n",
    "fig, ax =plt.subplots(nrows=2, ncols=1,figsize = (15,15))\n",
    "sns.despine(top=False, right=True, left=True)\n",
    "\n",
    "ax1 =sns.countplot(\"accident_seriousness\", hue=\"year\", hue_order=year_order,\n",
    "              palette=\"plasma\", data=not_serious, ax=ax[0])\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    ax1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/nstotal*100),\n",
    "            ha=\"center\",fontsize=12) \n",
    "    \n",
    "ax2 =  sns.countplot(\"accident_seriousness\", hue=\"year\", hue_order=year_order,\n",
    "              palette=\"plasma\", data=serious, ax=ax[1])\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 4,\n",
    "            '{:1.2f}%'.format(height/setotal*100),\n",
    "            ha=\"center\",fontsize=12)\n",
    "    \n",
    "fig.suptitle(\"Accidents by Year\", fontsize=18, fontweight=\"bold\")\n",
    "ax1.set_xlabel('Not Serious Accidents by Year\\n', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_xlabel('Serious Accidents by Year', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.set_ylabel('Number of Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax2.set_ylabel('Number of Accidents', fontsize=13.5, fontweight=\"bold\")\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.savefig('year.png')\n",
    "fig.show()\n",
    "\n",
    "### Visualization Summary\n",
    "* <b>did_police_officer_attend_scene_of_accident:</b> Police attended most accidents but were less likely to NOT be called in serious accidents.\n",
    "* <b>x1st_point_of_impact:</b> Majority of accidents were front impacted as the first point of impact. Not serious accidents had a higher percentage of Back impact accidents than serious accidents. Serious accidents had higher percentages of Offside and Nearside accidents. \n",
    "* <b>number_of_vehicles:</b>  Nothing significant.\n",
    "* <b>speed_limit:</b> Majority of accidents occurred in 30 speed limit zones. It would have been beneficial to have actual data on the speeds of the vehicles involved or at least if they were speeding.\n",
    "* <b>urban_or_rural_area:</b> Rural areas had a higher percentage of serious accidents. This may relate to hospital locations or emergency vehicle arrival data which was not available.\n",
    "* <b>skidding_and_overturning:</b> Higher percentages of serious accidents involved skidding, jackknifing or overturning.\n",
    "* <b>vehicle_leaving_carriageway:</b> Most vehicles did not leave the carriageway in either type of accident, however serious accidents had higher percentages of those that did leave the carriageway.\n",
    "* <b>sex_of_driver:</b> Men were more involved in both serious and not serious accidents, however according to racfoundation.org, there are only 355 of female privately registered cars on UK roads.\n",
    "* <b>vehicle_type:</b>  Motorcycles were involved in a significantly higher percentage of serious accidents than not serious accidents\n",
    "* <b>vehicle_manoeuvre:</b> Nothing significant.                      \n",
    "* <b>driver_home_area_type:</b> Rural and Small Towns has higher percentages of serious accidents. This may relate to hospital locations or emergency vehicle arrival data which was not available.\n",
    "* <b>age_band_of_driver:</b> The age bands over the age of 25 had a higher percentage of serious accidents than not serious.\n",
    "* <b>junction_control:</b>  Most areas with accidents were uncontrolled. \n",
    "* <b>hit_object_off_carriageway:</b> The majority of accidents did not involve objects being hit off the carriageway, however serious accidents had higher percentages of accidents that did involve hitting an object off the carriageway.\n",
    "* <b>hit_object_in_carriageway:</b> Most accidents did not involve objects being hit in the carriageway; however serious accidents had higher percentages of accidents that did involve hitting an object off the carriageway.\n",
    "* <b>driver_imd_decile:</b> Nothing significant. Most accidents occurred in areas that were Less deprived 20-30%\n",
    "* <b>junction_detail:</b> T or staggered junctions were where most of the accidents occurred.\n",
    "* <b>junction_location:</b> Nothing that separates the two serious types. However, most accidents seem to have occurred in Mid Junction - on roundabout or on main road or situations where the driver was approaching junction or waiting/parked at junction approach.\n",
    "* <b>propulsion_code:</b> Diesel, Fuel cells, New fuel technology, vehicles were not recorded as a part of serious accidents.\n",
    "* <b>year:</b> There has been a spike in percentage of serious accidents over the years. However, the percentage of not serious accidents has remained somewhat consistent\n",
    "### Other Visualizations\n",
    "\n",
    "Due to the previous visualizations a comparison of certain variables was desired to see more correlations.\n",
    "\n",
    "#### Junction Control by Junction Detail\n",
    "The following graph shows what type of traffic control were in specific areas of the road where accidents occured.\n",
    "#Not Serious Accident\n",
    "plt.figure(figsize=(20,15))\n",
    "ax=sns.countplot(\"junction_control\", hue=\"junction_detail\",\n",
    "              palette=\"plasma\", data=df)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.title(\"Junction Control by Junction Detail\",fontsize=25,fontweight=\"bold\")\n",
    "plt.xlabel(\"\\nAccident by Year\", fontsize=15, fontweight=\"bold\")\n",
    "plt.legend().set_title('')\n",
    "plt.legend(fontsize='22', loc = 'upper right')\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize='15', bbox_to_anchor=(1.04, 1), loc='upper right', ncol=1)\n",
    "# plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "sns.despine(top=True, right=True, left=True, bottom=False)\n",
    "plt.savefig('junction_control_by_junction_detail.png')\n",
    "plt.show()\n",
    "\n",
    "#### Junction Control by Junction Location\n",
    "The graph below is a more detailed look at junction areas in relation to the accidents.\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "ax=sns.countplot(\"junction_control\", hue=\"junction_location\",\n",
    "              palette=\"plasma\", data=df)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.title(\"Junction Control by Junction Location in Accidents\",fontsize=25,fontweight=\"bold\")\n",
    "plt.xlabel(\"\\nAccident by Year\", fontsize=15, fontweight=\"bold\")\n",
    "plt.legend().set_title('')\n",
    "plt.legend(fontsize='22', loc = 'upper right')\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize='15', bbox_to_anchor=(1.04, 1), loc='upper right', ncol=1)\n",
    "# plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "sns.despine(top=True, right=True, left=True, bottom=False)\n",
    "plt.savefig('junction_control_by_junction_location.png')\n",
    "plt.show()\n",
    "#### First point of Impact by Junction Detail\n",
    "The graph below shows where impact first occured in the detailed road area type.\n",
    "plt.figure(figsize=(20,15))\n",
    "ax=sns.countplot(\"x1st_point_of_impact\", hue=\"junction_detail\",\n",
    "              palette=\"plasma\", data=df)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.title(\"First point of Impact by Junction Detail\",fontsize=25,fontweight=\"bold\")\n",
    "plt.xlabel(\"\\nAccident by Year\", fontsize=15, fontweight=\"bold\")\n",
    "plt.legend().set_title('')\n",
    "plt.legend(fontsize='22', loc = 'upper right')\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize='15', bbox_to_anchor=(1.04, 1), loc='upper right', ncol=1)\n",
    "# plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "sns.despine(top=True, right=True, left=True, bottom=False)\n",
    "plt.savefig('x1st_point_of_impact_by_junction_detail.png')\n",
    "plt.show()\n",
    "#### First point of Impact by Junction Location\n",
    "The graph below shows where the accident occured and what was the first point of impact.\n",
    "plt.figure(figsize=(20,15))\n",
    "ax=sns.countplot(\"x1st_point_of_impact\", hue=\"junction_location\",\n",
    "              palette=\"plasma\", data=df)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.title(\"First point of Impact by Junction Location\",fontsize=25,fontweight=\"bold\")\n",
    "plt.xlabel(\"\\nAccident by Year\", fontsize=15, fontweight=\"bold\")\n",
    "plt.legend().set_title('')\n",
    "plt.legend(fontsize='22', loc = 'upper right')\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize='15', bbox_to_anchor=(1.04, 1), loc='upper right', ncol=1)\n",
    "# plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "sns.despine(top=True, right=True, left=True, bottom=False)\n",
    "plt.savefig('x1st_point_of_impact_by_junction_location.png')\n",
    "plt.show()\n",
    "#### Junction Control and First Point of Impact\n",
    "The following graph shows what type of traffic controls (signange or otherwise) were present at the first point of impact.\n",
    "plt.figure(figsize=(20,15))\n",
    "ax=sns.countplot(\"x1st_point_of_impact\", hue=\"junction_control\",\n",
    "              palette=\"plasma\", data=df)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.title(\"First point of Impact by Junction Control\",fontsize=25,fontweight=\"bold\")\n",
    "plt.xlabel(\"\\nAccident by Year\", fontsize=15, fontweight=\"bold\")\n",
    "plt.legend().set_title('')\n",
    "plt.legend(fontsize='22', loc = 'upper right')\n",
    "plt.ylabel(\"\\nNumber of Accidents\", fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(fontsize='15', bbox_to_anchor=(1.04, 1), loc='upper right', ncol=1)\n",
    "# plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "sns.despine(top=True, right=True, left=True, bottom=False)\n",
    "plt.savefig('x1st_point_of_impact_by_junction_control.png')\n",
    "plt.show()\n",
    "### Other Visualizations Summary\n",
    "No matter the situation above, the most accidents were involving areas that were uncontrolled. One of the main ones were the junction Detail T or staggered junction.\n",
    "\n",
    "Other areas of concern include Mid Junctions on roundabouts or main roads and areas approaching a junction were cars were either parking or waiting in the junction. \n",
    "\n",
    "### Solution\n",
    "\n",
    "From the data above more controlled areas would be benefical. Maybe signs alerting drivers of the upcoming junctions, traffic lights, or stop signs would help in some of these areas where they are feasible. \n",
    "\n",
    "![staggered-junctions.jpg](https://raw.githubusercontent.com/GenTaylor/Traffic-Accident-Analysis/master/staggered-junctions.jpg)\n",
    "\n",
    "For example, this is a staggered junction, the main junction detail in accidents. One can understand how a situation such as these can lead to numerous accidents especially if proper signage is not available. Perhaps traffic lights, stop signs, or warnings indicating that they are approaching certain junctions would help reduce accidents.\n",
    "#### Web Scraping\n",
    "Below you wll find a web scrape of the website, [Learner Driving Centres](https://www.learnerdriving.com/learn-to-drive/highway-code/road-signs), which contains information on road signs in the UK. They were pulled to show examples of signage available to be placed. \n",
    "#request website\n",
    "r = requests.get('https://www.learnerdriving.com/learn-to-drive/highway-code/road-signs')\n",
    "\n",
    "#parse HTML\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "#filter results\n",
    "results = soup.find_all('div', attrs={'class':'fifth'})\n",
    "#done to find specific results area\n",
    "first_result=results[0]\n",
    "first_result\n",
    "first_result.find('img')['src']\n",
    "#get images of signs and sign descriptions \n",
    "signage = []\n",
    "for result in results:\n",
    "    sign=result.find('img')['src']\n",
    "    sign_desc=result.contents[1]\n",
    "    signage.append((sign, sign_desc))\n",
    "#put pulled UK Traffic Signs into dataframe\n",
    "uktrafficsigns = pd.DataFrame(signage, columns=['Sign', 'Sign Description'])\n",
    "uktrafficsigns.head()\n",
    "'''\n",
    "the \"image\" is just part of the image link, \n",
    "must parse the first half in order to have full image link\n",
    "\n",
    "'''\n",
    "uktrafficsigns['Sign'] = 'https://www.learnerdriving.com/'+uktrafficsigns['Sign'] \n",
    "uktrafficsigns.head()\n",
    "'''\n",
    "In some coding below I saw that one of the fields was blank (at index 42) but was not reading as null.\n",
    "In order to fix that I changed the \"Sign Description\" and decided to place it here.\n",
    "'''\n",
    "uktrafficsigns.at[42,'Sign Description']=\"T-junction with priority over vehicles from the right\"\n",
    "#I wanted to save this as a csv for later, and to stop unnecessary web scraping\n",
    "uktrafficsigns.to_csv('uktrafficsigns.csv', header=False, index=False) \n",
    "#I wanted the html to show up as images instead of links\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\" width=\"60\" >'\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "ukts=HTML(uktrafficsigns.to_html(escape=False ,formatters=dict(Sign=path_to_image_html)))\n",
    "HTML(uktrafficsigns.to_html(escape=False ,formatters=dict(Sign=path_to_image_html)))\n",
    "'''\n",
    "Here I am creating a df that will allow me to pull all junction signs.\n",
    "\"ction\" was used instead of \"junction\" in order to pull all variables.\n",
    "'''\n",
    "junction =uktrafficsigns[uktrafficsigns['Sign Description'].str.contains(\"nction\", regex=False)]\n",
    "\n",
    "#Making it its own HTML object (same as above)\n",
    "\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\" width=\"60\" >'\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "HTML(junction.to_html(escape=False ,formatters=dict(Sign=path_to_image_html)))\n",
    "\n",
    "#Repeated the above steps for giveways\n",
    "give=uktrafficsigns[uktrafficsigns['Sign Description'].str.contains(\"ive \", regex=False)]\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\" width=\"60\" >'\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "HTML(give.to_html(escape=False ,formatters=dict(Sign=path_to_image_html)))\n",
    "#roundabouts\n",
    "roundabout=uktrafficsigns[uktrafficsigns['Sign Description'].str.contains(\"ounda\", regex=False)]\n",
    "\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\" width=\"60\" >'\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "HTML(roundabout.to_html(escape=False ,formatters=dict(Sign=path_to_image_html)))\n",
    "#### Mapping of Problem Areas\n",
    "Below we used Tableau to map what could be deemed problem areas for the UK. These are accidents in areas with high deprivation (driver_imd_decile @ more deprived 40-50%)  and no signange at T or staggered junctions.<br>\n",
    "%%HTML\n",
    "\n",
    "<div class='tableauPlaceholder' id='viz1572177057382' style='position: relative'><noscript><a href='https:&#47;&#47;github.com&#47;GenTaylor&#47;Traffic-Accident-Analysis'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ac&#47;AccidentForecasting&#47;SeriousAccidentsinAreaswithHighDeprivationandNoSignage&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='AccidentForecasting&#47;SeriousAccidentsinAreaswithHighDeprivationandNoSignage' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ac&#47;AccidentForecasting&#47;SeriousAccidentsinAreaswithHighDeprivationandNoSignage&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1572177057382');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>\n",
    "Below is a screenshot of the above mapping. I put this here just in case there is trouble viewing it. If you would like to view the actual worksheet for it, please click [here](https://public.tableau.com/profile/genesis.taylor#!/vizhome/AccidentForecasting/SeriousAccidentsinAreaswithHighDeprivationandNoSignage).\n",
    "\n",
    "![mapping.PNG](https://raw.githubusercontent.com/GenTaylor/Traffic-Accident-Analysis/master/mapping.PNG)\n",
    "## Machine Learning\n",
    "#made separate dataframe w. set index that wouldnt effect data vis above\n",
    "df1=df\n",
    "#set index to accident_index\n",
    "df1.set_index('accident_index', inplace=True)\n",
    "df1.head()\n",
    "df1 = df1.drop(['accident_severity'],axis=1)\n",
    "df1.head()\n",
    "print(df1.columns)\n",
    "### Preprocessing\n",
    "#separate dtypes\n",
    "notif=df1.select_dtypes(exclude=['int','float','int64'])\n",
    "intfldtypes = df1.select_dtypes(include=['int','float','int64'])\n",
    "print('Objects',notif.columns)\n",
    "print(\"\\nNonObjects\",intfldtypes.columns)\n",
    "\n",
    "#checking to make sure all are accounted for\n",
    "print(df1.shape)\n",
    "print(notif.shape)\n",
    "print(intfldtypes.shape)\n",
    "Label Encoder was used instead of OneHotEncoder due to the memory errors One Hot Encoder caused in the data. The algorithms used will be classifiers, through boosting and trees, and not linear. \n",
    "#label encode objects\n",
    "obj_le= notif.apply(LabelEncoder().fit_transform)\n",
    "#re-add with non-objects\n",
    "df_ml= pd.concat([obj_le,intfldtypes], axis=1, sort=False)\n",
    "#check shape\n",
    "print(df_ml.shape)\n",
    "#Set up of X and Y\n",
    "X= df_ml.drop(['accident_seriousness'],axis=1)\n",
    "y= df_ml['accident_seriousness']\n",
    "df_ml.accident_seriousness.value_counts()\n",
    "df.dtypes\n",
    "plt.figure(figsize=(12,6))\n",
    "ax=sns.countplot(x=\"accident_seriousness\", palette=\"magma\", data=df)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.title(\"Accident Seriousness\",fontsize=25,fontweight=\"bold\")\n",
    "plt.xlabel(\"\", fontsize=15, fontweight=\"bold\")\n",
    "plt.ylabel(\"\\nNumber of Accidents\\n\", fontsize=15, fontweight=\"bold\")\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=12)\n",
    "sns.despine(top=True, right=True, left=True, bottom=False)\n",
    "plt.savefig('accident_seriousness.png')\n",
    "plt.show()\n",
    "### Imbalanced Data\n",
    "The data in this dataset is extremely imbalanced for what we are trying to predict. We are going to resample the data as undersampling, where we reduce the number of majority (Not Serious Accidents) samples.<br><br> \n",
    "***\n",
    "The machine learning classifier algorithms that we are going to use are as follows:\n",
    "* Bagging Classifier (sklearn)\n",
    "* AdaBoost Classifier (sklearn)\n",
    "* Random Forest Classifier (sklearn)\n",
    "* Gradient Boosting Classifier (sklearn)*\n",
    "* LightGBM Classifier (LightGBM)\n",
    "* XGBoost Classifier (xgboost)\n",
    "* Balanced Bagging Classifier(imblearn)\n",
    "* Balanced Random Forest Classifier (imblearn) \n",
    "* Easy Ensemble Classifier (imblearn)<br><br>\n",
    "***\n",
    "*Gradient Boosting was commented out because of the time it took to run (18hrs) and not having relevant enough results to still consider.\n",
    "### Resample: Undersampling\n",
    "# setting up testing and training sets\n",
    "res_X_train, res_X_test, res_y_train, res_y_test = train_test_split(X, y, \n",
    "                                                                    test_size=0.25, random_state=27)\n",
    "# concatenate our training data back together\n",
    "res_X = pd.concat([res_X_train, res_y_train], axis=1)\n",
    "# separate minority and majority classes\n",
    "not_severe = res_X[res_X.accident_seriousness==0]\n",
    "severe = res_X[res_X.accident_seriousness==1]\n",
    "# decrease majority\n",
    "not_severe_decreased = resample(not_severe,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(severe), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "# combine majority and severe_increased minority\n",
    "newdf = pd.concat([severe, not_severe_decreased])\n",
    "newdf.accident_seriousness.value_counts()\n",
    "res_X_train = newdf.drop('accident_seriousness', axis=1)\n",
    "res_y_train = newdf.accident_seriousness\n",
    "### Unsupervised Learning\n",
    "Before, we get in to predictions, we are going to complete some machine learning in ordered to see how the data relates to each other.\n",
    "We are going to do this on the resampled data as well, in order to avoid bias. We will use two clusters which, in theory, represent the two variables for accident_seriousness, Not Serious & Serious\n",
    "# \"clustering\" using kmode algorithm that is designed to handle mixed data\n",
    "km_huang = KModes(n_clusters=2, init = \"Huang\", n_init = 1)\n",
    "fitClusters_huang = km_huang.fit_predict(newdf)\n",
    "fitClusters_huang\n",
    "newdf1 = newdf.copy().reset_index()\n",
    "clustersDf = pd.DataFrame(fitClusters_huang)\n",
    "clustersDf.columns = ['cluster_predicted']\n",
    "combinedDf = pd.concat([newdf1, clustersDf], axis = 1).reset_index()\n",
    "combinedDf = combinedDf.drop(['index'], axis = 1)\n",
    "combinedDf.head()\n",
    "#plotting a few of these features just to see how they relate to the clustering for seriousness\n",
    "f, axs = plt.subplots(nrows=6, ncols=3,figsize = (12,24))\n",
    "plt.style.use('dark_background')\n",
    "sns.countplot(x=combinedDf['did_police_officer_attend_scene_of_accident'],\n",
    "              order=combinedDf['did_police_officer_attend_scene_of_accident'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[0,0])\n",
    "sns.countplot(x=combinedDf['x1st_point_of_impact'],\n",
    "              order=combinedDf['x1st_point_of_impact'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[0,1])\n",
    "sns.countplot(x=combinedDf['number_of_vehicles'],\n",
    "              order=combinedDf['number_of_vehicles'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[0,2])\n",
    "sns.countplot(x=combinedDf['speed_limit'],\n",
    "              order=combinedDf['speed_limit'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[1,0])\n",
    "sns.countplot(x=combinedDf['urban_or_rural_area'],\n",
    "              order=combinedDf['urban_or_rural_area'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[1,1])\n",
    "sns.countplot(x=combinedDf['skidding_and_overturning'],\n",
    "              order=combinedDf['skidding_and_overturning'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[1,2])\n",
    "sns.countplot(x=combinedDf['vehicle_leaving_carriageway'],\n",
    "              order=combinedDf['vehicle_leaving_carriageway'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[2,0])\n",
    "sns.countplot(x=combinedDf['sex_of_driver'],\n",
    "              order=combinedDf['sex_of_driver'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[2,1])\n",
    "sns.countplot(x=combinedDf['vehicle_type'],\n",
    "              order=combinedDf['vehicle_type'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[2,2])\n",
    "sns.countplot(x=combinedDf['junction_control'],\n",
    "              order=combinedDf['junction_control'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[3,0])\n",
    "sns.countplot(x=combinedDf['number_of_casualties'],\n",
    "              order=combinedDf['number_of_casualties'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[3,1])\n",
    "sns.countplot(x=combinedDf['age_band_of_driver'],\n",
    "              order=combinedDf['age_band_of_driver'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[3,2])\n",
    "sns.countplot(x=combinedDf['junction_detail'],\n",
    "              order=combinedDf['junction_detail'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[4,0])\n",
    "sns.countplot(x=combinedDf['junction_location'],\n",
    "              order=combinedDf['junction_location'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[4,1])\n",
    "sns.countplot(x=combinedDf['driver_imd_decile'],\n",
    "              order=combinedDf['driver_imd_decile'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[4,2])\n",
    "sns.countplot(x=combinedDf['junction_detail'],\n",
    "              order=combinedDf['junction_detail'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[5,0])\n",
    "sns.countplot(x=combinedDf['junction_location'],\n",
    "              order=combinedDf['junction_location'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[5,1])\n",
    "sns.countplot(x=combinedDf['driver_imd_decile'],\n",
    "              order=combinedDf['driver_imd_decile'].value_counts().index,\n",
    "              hue=combinedDf['cluster_predicted'], palette='PuBu', ax=axs[5,2])\n",
    "plt.tight_layout()\n",
    "plt.savefig('clusterplot.png')\n",
    "plt.show()\n",
    "Looking at these graphs we can see the patterns of how each category of eacch column pairs off with the clustering on accident_seriousness.\n",
    "### Supervised Learning with Resampling as Undersampling\n",
    "#confusion matrix plot function\n",
    "def cm_plot(var):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.style.use('dark_background')\n",
    "    plt.clf()\n",
    "    plt.imshow(var, interpolation='nearest', cmap='tab20')\n",
    "    classNames = ['Not Serious','Serious']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual\\n')\n",
    "    plt.xlabel('Predicted\\n')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\"=\"+str(var[i][j]),horizontalalignment='center', \n",
    "                     color='black')\n",
    "    plt.show()\n",
    "#### Method 1\n",
    "##First, we are going to run some standard classifier algorithms using the resampling method from above, gather the results of some scoring metrics (Accuracy, Log Loss, Cross Validation, Recall, Roc Auc, F1, False Positive Rate, Error Rate), and put those scores into a dataframe\n",
    "#Try modeling using  different classification models\n",
    "classifiers = [\n",
    "    BaggingClassifier(max_features=X.shape[1], n_estimators=500, random_state=42),\n",
    "    AdaBoostClassifier( n_estimators=500, learning_rate=0.05, random_state=42),\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=40,max_features=X.shape[1], \n",
    "                           min_samples_split=8, n_estimators=500, random_state=42),\n",
    "    LGBMClassifier(learning_rate =0.03, max_depth=40, min_data_in_leaf=10,\n",
    "                   n_estimators=500, num_leaves=50, random_state = 42),\n",
    "    XGBClassifier(learning_rate=0.05, n_estimators=500, subsample= 1,random_state = 42,\n",
    "                        gamma = 1, max_depth=40)]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#putting results in df\n",
    "res_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\", \"Cross Val\", \"Recall\", \"Roc Auc\",\"F1\", \n",
    "          \"False Positive Rate\", \"Error Rate\"]\n",
    "results = pd.DataFrame(columns=res_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(res_X_train, res_y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"\\n\"*3)\n",
    "    print(name,\"Results:\")\n",
    "       \n",
    "    print('~'*40)\n",
    "    y_pred = clf.predict(res_X_test)\n",
    "    acc = accuracy_score(res_y_test, y_pred)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    cv= np.mean(cross_val_score(clf, res_X_train, res_y_train, cv=3))\n",
    "    print(\"Cross validation scores:\",cv)\n",
    "    \n",
    "    \n",
    "    train_predictions = clf.predict_proba(res_X_test)\n",
    "    logloss = log_loss(res_y_test, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(logloss))\n",
    "    \n",
    "    cm = confusion_matrix(res_y_test, y_pred)\n",
    "    \n",
    "    cm_plot(cm)\n",
    "    \n",
    "    #FPR and Error Rate setup\n",
    "    tn, fp, fn, tp = confusion_matrix(res_y_test,y_pred).ravel()\n",
    "    \n",
    "    fpr = fp/(tn+fp)\n",
    "    ers = 1-acc\n",
    "    rec= recall_score(res_y_test, y_pred)\n",
    "    roc=roc_auc_score(res_y_test, y_pred)\n",
    "    f1s=f1_score(res_y_test, y_pred)\n",
    "    results_final = pd.DataFrame([[name, round(acc*100,3), round(logloss,3), \n",
    "                                   round(cv*100,3), round(rec*100,3), round(roc*100,3),\n",
    "                                   round(f1s*100,3),round(fpr*100,3),round(ers*100,3)]],\n",
    "                                 columns=res_cols)\n",
    "    results = results.append(results_final)\n",
    "    \n",
    "print(\"*\"*40)\n",
    "print(\"Results Shape\",results.shape)\n",
    "results.head(10)\n",
    "#### Method 2\n",
    "For the following Balanced algorithms from imblearn we will be using the standard testing and training sets (X_train, X_test, y_train, y_test) and will allow the algorithms to do the resampling.<br> <br>For the sampling_strategy, we will be using majority as the solution.<br><br>'majority': resample only the majority class\n",
    "\n",
    "We will then gather the results of some scoring metrics (Accuracy, Log Loss, Cross Validation, Recall, Roc Auc, F1, False Positive Rate, Error Rate), and put those scores into a dataframe.\n",
    "#train_tes_split without resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "#Try modeling using  different classification models\n",
    "classifiers2 = [\n",
    "    BalancedBaggingClassifier(max_features=X.shape[1], n_estimators=500, replacement=True,\n",
    "                              sampling_strategy='majority', random_state=42),\n",
    "    EasyEnsembleClassifier(n_estimators=500, random_state=42, replacement=True,\n",
    "                           sampling_strategy='majority'),\n",
    "    BalancedRandomForestClassifier(criterion='entropy', max_depth=40,min_samples_leaf = 1, \n",
    "                                   max_features=X.shape[1], sampling_strategy='majority', \n",
    "                                   replacement=True, min_samples_split=8, n_estimators=500,\n",
    "                                   random_state=42)]\n",
    "\n",
    "#putting results in df\n",
    "res_cols2=[\"Classifier\", \"Accuracy\", \"Log Loss\", \"Cross Val\", \"Recall\", \"Roc Auc\",\"F1\", \n",
    "          \"False Positive Rate\", \"Error Rate\"]\n",
    "results2 = pd.DataFrame(columns=res_cols2)\n",
    "\n",
    "for clf2 in classifiers2:\n",
    "    clf2.fit(X_train, y_train)\n",
    "    name2 = clf2.__class__.__name__\n",
    "    \n",
    "    print(\"\\n\"*3)\n",
    "    print(name2,\"Results:\")\n",
    "       \n",
    "    print('~'*40)\n",
    "    y_pred2 = clf2.predict(X_test)\n",
    "    acc2 = accuracy_score(y_test, y_pred2)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc2))\n",
    "    \n",
    "    cv2= np.mean(cross_val_score(clf2, X_train, y_train, cv=3))\n",
    "    print(\"Cross validation scores:\",cv2)\n",
    "    \n",
    "    \n",
    "    train_predictions2 = clf2.predict_proba(X_test)\n",
    "    logloss2 = log_loss(y_test, train_predictions2)\n",
    "    print(\"Log Loss: {}\".format(logloss2))\n",
    "    \n",
    "    cm2 = confusion_matrix(y_test, y_pred2)\n",
    "    \n",
    "    cm_plot(cm2)\n",
    "    \n",
    "    #FPR and Error Rate setup\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred2).ravel()\n",
    "    \n",
    "    fpr2 = fp/(tn+fp)\n",
    "    ers2 = 1-acc\n",
    "    rec2= recall_score(y_test, y_pred2)\n",
    "    roc2=roc_auc_score(y_test, y_pred2)\n",
    "    f1s2=f1_score(y_test, y_pred2)\n",
    "    results_final2 = pd.DataFrame([[name2, round(acc2*100,3), round(logloss2,3), \n",
    "                                   round(cv2*100,3), round(rec2*100,3), round(roc2*100,3),\n",
    "                                   round(f1s2*100,3),round(fpr2*100,3),round(ers2*100,3)]],\n",
    "                                 columns=res_cols2)\n",
    "    results2 = results2.append(results_final2)\n",
    "    \n",
    "print(\"*\"*40)\n",
    "print(\"Results 2 Shape\",results2.shape)\n",
    "results2.head(10)\n",
    "We will now combine the dataframes from both methods into one datframe for analyzing and visualizations\n",
    "ml_results = pd.concat([results,results2])\n",
    "print(\"Shape\",ml_results.shape)\n",
    "ml_results.head(10)\n",
    "#save to csv\n",
    "ml_results.to_csv('ml_results.csv')\n",
    "#Visualize scores for all model\n",
    "\n",
    "fig, ax =plt.subplots(nrows=8, ncols=1, figsize = (11,18))\n",
    "plt.style.use('dark_background')\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=ml_results, palette='plasma', ax=ax[0])\n",
    "sns.barplot(x='Log Loss', y='Classifier', data=ml_results, palette='plasma', ax=ax[1])\n",
    "sns.barplot(x='Cross Val', y='Classifier', data=ml_results, palette='plasma', ax=ax[2])\n",
    "sns.barplot(x='Recall', y='Classifier', data=ml_results, palette='plasma', ax=ax[3])\n",
    "sns.barplot(x='Roc Auc', y='Classifier', data=ml_results, palette='plasma', ax=ax[4])\n",
    "sns.barplot(x='F1', y='Classifier', data=ml_results, palette='plasma', ax=ax[5])\n",
    "sns.barplot(x='False Positive Rate', y='Classifier', data=ml_results, palette='plasma', ax=ax[6])\n",
    "sns.barplot(x='Error Rate', y='Classifier', data=ml_results, palette='plasma', ax=ax[7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "##### Choice\n",
    "\n",
    "Based on the visualizations above, Balanced Bagging Classifier from imblearn is the algorithm of choice for this data. While some of the scores may have been close, Balanced Bagging Classifier had higher scores in Accuracy, Cross Validation, and Specificity. The algorithm also had the lower Error Rate and False Positive Rates of the group.\n",
    "#### Balanced Bagging Classifier with LightGBM\n",
    "Balanced Bagging Classifier performed thest best of the classifiers, however, I was not comfortable with how close  its predictions were for Serious Accidents in the confusion matrix. Due to this, I decided to combine Balanced Bagging Classifier with the second highest performing algorithm, LightGBM to see what results I would get.\n",
    "#start\n",
    "start_res_bbag_w_lgbm = time.time()\n",
    "\n",
    "# Balanced Bagging Classifier\n",
    "res_bbag_w_lgbm = BalancedBaggingClassifier(base_estimator=LGBMClassifier(learning_rate =0.03, \n",
    "                                                                          max_depth=40, \n",
    "                                                                          min_data_in_leaf=10,\n",
    "                                                                          n_estimators=500, \n",
    "                                                                          num_leaves=50, \n",
    "                                                                          random_state = 42), \n",
    "                                            max_features=X.shape[1], n_estimators=500, \n",
    "                                            replacement=True, sampling_strategy='majority', \n",
    "                                            random_state=42)\n",
    "\n",
    "res_bbag_w_lgbm.fit(X_train, y_train)\n",
    "pred_res_bbag_w_lgbm = res_bbag_w_lgbm.predict(X_test)\n",
    "\n",
    "   \n",
    "# Creates a confusion matrix\n",
    "res_bbag_w_lgbm_cm = confusion_matrix(y_test,pred_res_bbag_w_lgbm)\n",
    "\n",
    "# Transform to df for easier plotting\n",
    "res_bbag_w_lgbm_cm_df = pd.DataFrame(res_bbag_w_lgbm_cm,\n",
    "                     index = ['Not Serious','Serious'], \n",
    "                     columns = ['Not Serious','Serious'])\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.style.use('dark_background')\n",
    "sns.heatmap(res_bbag_w_lgbm_cm_df, annot=True, fmt=\"d\", cmap='viridis', linecolor='black', linewidths=1)\n",
    "plt.title('Resampled Balanced Bagging with LightGBM Accuracy: {0:.2f}%'.format(accuracy_score(y_test,pred_res_bbag_w_lgbm )*100),\n",
    "          fontsize=15)\n",
    "plt.ylabel('Actual\\n')\n",
    "plt.xlabel('Predicted\\n')\n",
    "plt.show()\n",
    "# print(\"Resampled Balanced Bagging with LightGBM Classifier Cross Validation Score: {:0.2f}%\"\n",
    "#       .format(np.mean(cross_val_score(res_bbag_w_lgbm, X_train, y_train, cv=3)*100)))\n",
    "print('Cross Val Score was 69.67%. It was commented out here to save time when re-running.') \n",
    "print('Check UK_Road_Safety_Traffic_Accidents_and_Vehicles(old).ipynb to see proof')\n",
    "print('\\n')\n",
    "#end\n",
    "end_res_bbag_w_lgbm = time.time()\n",
    "print(\"\\nResampled Balanced Bagging with LightGBM Time: \",end_res_bbag_w_lgbm - start_res_bbag_w_lgbm)\n",
    "#extracting true_positives, false_positives, true_negatives, false_negatives\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,pred_res_bbag_w_lgbm).ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test,pred_res_bbag_w_lgbm)*100\n",
    "specificity = tn/(tn+fp)*100\n",
    "fpr = fp/(tn+fp)*100\n",
    "ers = 100-accuracy\n",
    "\n",
    "\n",
    "train_predictions2 = res_bbag_w_lgbm.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM Specificity Score: {0:.2f}%\".format(specificity))\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM False Positive Rate Score: {0:.2f}%\".format(fpr))\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM Error Rate Score: {0:.2f}%\".format(ers))\n",
    "\n",
    "#Check scores\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_res_bbag_w_lgbm )*100))\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_res_bbag_w_lgbm,average=\"macro\")*100))\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM Precision Scoreres_: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_res_bbag_w_lgbm, average=\"macro\")*100))\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_res_bbag_w_lgbm, average=\"macro\")*100))\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM Roc Auc Score: {0:.2f}%\"\n",
    "      .format(roc_auc_score(y_test, pred_res_bbag_w_lgbm)*100))\n",
    "print(\"Resampled Balanced Bagging Classifier with LightGBM Log Loss {0:.2f}%\"\n",
    "      .format(log_loss(y_test, train_predictions2)*100))\n",
    "The results were better than the other learning algorithms but lower accuracy wise than the previous Balanced Bagging Algorithm. Taking all of that into consideration, I have decided that depending on what was the goal, either Balanced Bagging Classifier algorithm could be used. If I were more concerned with overall accuracy, the regular Balanced Bagging Classifier would be used. If I were more concerned with making sure \"Serious\" predictions were achieved, Balanced Bagging Classifier with LightGBM would be used.\n",
    "ml_results = ml_results.append(pd.Series([\"BalancedBaggingClassifierW/LGBM\", 69.140,0.582,\n",
    "                                          69.670,68.240,68.240,57.140,30.570,30.860],\n",
    "                                         index=ml_results.columns),ignore_index=True)\n",
    "ml_results.head(10)\n",
    "#Visualize scores for all model\n",
    "\n",
    "fig, ax =plt.subplots(nrows=8, ncols=1, figsize = (11,18))\n",
    "plt.style.use('dark_background')\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=ml_results, palette='plasma', ax=ax[0])\n",
    "sns.barplot(x='Log Loss', y='Classifier', data=ml_results, palette='plasma', ax=ax[1])\n",
    "sns.barplot(x='Cross Val', y='Classifier', data=ml_results, palette='plasma', ax=ax[2])\n",
    "sns.barplot(x='Recall', y='Classifier', data=ml_results, palette='plasma', ax=ax[3])\n",
    "sns.barplot(x='Roc Auc', y='Classifier', data=ml_results, palette='plasma', ax=ax[4])\n",
    "sns.barplot(x='F1', y='Classifier', data=ml_results, palette='plasma', ax=ax[5])\n",
    "sns.barplot(x='False Positive Rate', y='Classifier', data=ml_results, palette='plasma', ax=ax[6])\n",
    "sns.barplot(x='Error Rate', y='Classifier', data=ml_results, palette='plasma', ax=ax[7])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "ml_results.to_csv('ml_results_final_results.csv')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
